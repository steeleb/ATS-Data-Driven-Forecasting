{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script walks through a forecast for SMR using the NN-operational model developed in the NASA-NW repo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#high level modules\n",
    "import os\n",
    "import imp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom modules\n",
    "this_dir = \"/Users/steeleb/Documents/GitHub/ats-data-driven-forecasting/NN-operational/arNN/\"\n",
    "\n",
    "imp.load_source(\"universals\", os.path.join(this_dir, \"universal_functions.py\"))\n",
    "from universals import load_pickle_file, twotemp_labels_features_test, predict_2_values_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"/Users/steeleb/Documents/GitHub/ats-data-driven-forecasting/data/NN_train_val_test/SMR_forecast/models/leaky_basic_5/\"\n",
    "\n",
    "model_1 = load_pickle_file(\"model_1.pkl\", model_dir)\n",
    "model_2 = load_pickle_file(\"model_2.pkl\", model_dir)\n",
    "model_3 = load_pickle_file(\"model_3.pkl\", model_dir)\n",
    "model_4 = load_pickle_file(\"model_4.pkl\", model_dir)\n",
    "model_5 = load_pickle_file(\"model_5.pkl\", model_dir)\n",
    "model_6 = load_pickle_file(\"model_6.pkl\", model_dir)\n",
    "model_7 = load_pickle_file(\"model_7.pkl\", model_dir)\n",
    "model_8 = load_pickle_file(\"model_8.pkl\", model_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/Users/steeleb/Documents/GitHub/ats-data-driven-forecasting/data/NN_train_val_test/SMR_forecast/\"\n",
    "\n",
    "test = pd.read_csv(os.path.join(data_dir, \"t2022_standardized_v2024-10-28.csv\"))\n",
    "forecast = pd.read_csv(os.path.join(data_dir, \"t2022_forecast_std_v2024-10-28.csv\"))\n",
    "\n",
    "test[\"date\"] = pd.to_datetime(test[\"date\"])\n",
    "forecast[\"date\"] = pd.to_datetime(forecast[\"date\"])\n",
    "forecast[\"forecast_date\"] = pd.to_datetime(forecast[\"forecast_date\"])\n",
    "\n",
    "# we need the test columns to be the same as the forecast columns at the end of this, so grab the names for now\n",
    "forecast_cols = test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create function to roll out forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-20\n",
      "Forecasting day:  1\n",
      "         date  perturbation  model  mean_1m_temp_degC  mean_0_5m_temp_degC\n",
      "0  2022-08-20             0      1           0.361165            -0.189793\n",
      "1  2022-08-20             1      1           0.310787            -0.178734\n",
      "2  2022-08-20             2      1           0.256008            -0.171581\n",
      "3  2022-08-20             3      1           0.339003            -0.176153\n",
      "4  2022-08-20             4      1           0.325255            -0.176620\n",
      "..        ...           ...    ...                ...                  ...\n",
      "26 2022-08-20            26      8           0.184289            -0.243250\n",
      "27 2022-08-20            27      8           0.127128            -0.301402\n",
      "28 2022-08-20            28      8           0.209748            -0.282130\n",
      "29 2022-08-20            29      8           0.112261            -0.258826\n",
      "30 2022-08-20            30      8           0.127622            -0.418501\n",
      "\n",
      "[248 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "def make_forecast(date, n_days):\n",
    "    \n",
    "    print(date)\n",
    "    date = pd.to_datetime(date)\n",
    "    \n",
    "    # get the forecast data from a specific date\n",
    "    fore = forecast[forecast[\"forecast_date\"] == date].copy()\n",
    "    # earliest date is noon met for forecast. Calculatet the differencein dates and add as a column called \"offset\"\n",
    "    fore[\"offset\"] = (fore[\"date\"] - fore[\"forecast_date\"]).dt.days\n",
    "    # remove the date column and rename forecast_date to date\n",
    "    fore = fore.drop(columns=[\"forecast_date\"])\n",
    "    \n",
    "    # we'll run a forecast for each day, since the following day's forecast will be based on the previous day's forecast\n",
    "    for d in range(n_days):\n",
    "        # Setup for the iteration\n",
    "        print(\"Forecasting day: \", d+1)\n",
    "        # set the forecast date\n",
    "        forecast_date = pd.to_datetime(date) + pd.DateOffset(days=d)\n",
    "        obs = test[test[\"date\"] == forecast_date].copy()\n",
    "\n",
    "        # the first day will be a bit different from subsequent days\n",
    "        if d == 0:\n",
    "            # remove the noon met data\n",
    "            obs = obs.drop(columns=[\"noon_air_temp\", \"noon_ave_wind\", \"noon_solar_rad\"])\n",
    "            # grab the forecast data for the offset date\n",
    "            fore_select = fore[fore[\"offset\"] == d].copy()\n",
    "            # join fore_select with obs, drop offset columns, and use the number column as index\n",
    "            obs_fore = obs.join(fore_select.set_index(\"date\"), on=\"date\")\n",
    "            obs_fore = obs_fore.drop(columns=[\"offset\"])\n",
    "            obs_fore = obs_fore.set_index(\"number\")\n",
    "            # now reorganize the columns to match the input columns\n",
    "            obs_fore = obs_fore[forecast_cols]\n",
    "            \n",
    "            # preprocess the data into labels and features\n",
    "            features, labels = twotemp_labels_features_test(obs_fore)\n",
    "            \n",
    "            # make the forecast for each perturbation\n",
    "            pred_1 = model_1.predict(features)\n",
    "            pred_2 = model_2.predict(features)\n",
    "            pred_3 = model_3.predict(features)\n",
    "            pred_4 = model_4.predict(features)\n",
    "            pred_5 = model_5.predict(features)\n",
    "            pred_6 = model_6.predict(features)\n",
    "            pred_7 = model_7.predict(features)\n",
    "            pred_8 = model_8.predict(features)\n",
    "\n",
    "            # and now we need to create the dataframe for the next iteration\n",
    "            # first, create a dataframe with the forecast data\n",
    "            for i, pred in enumerate([pred_1, pred_2, pred_3, pred_4, pred_5, pred_6, pred_7, pred_8], start=1):\n",
    "                forecasted_temp = pd.DataFrame(columns=['date', 'perturbation', 'model', 'mean_1m_temp_degC', 'mean_0_5m_temp_degC'])\n",
    "                forecasted_temp[\"perturbation\"] = obs_fore.index\n",
    "                forecasted_temp['model'] = i\n",
    "                forecasted_temp[\"mean_1m_temp_degC\"] = [p[0] for p in pred]\n",
    "                forecasted_temp[\"mean_0_5m_temp_degC\"] = [p[1] for p in pred]\n",
    "                forecasted_temp[\"date\"] = forecast_date\n",
    "                # Append to the main dataframe\n",
    "                if 'all_forecasts' in locals():\n",
    "                    all_forecasts = pd.concat([all_forecasts, forecasted_temp])\n",
    "                else:\n",
    "                    all_forecasts = forecasted_temp.copy()\n",
    "        \n",
    "        # for all other days, we need to:\n",
    "        #   - use the forecast met data for d-offset for noon met data\n",
    "        #   - drop the _m7 met data columns\n",
    "        #   - rename the _m1, ..., _m6 columns to _m2, ..., _m7 for the met data columns\n",
    "        #   - drop the _m3 column of the mean_1m_temp_degC and mean_0_5m_temp_degC\n",
    "        #   - rename the _m1, _m2, _m3 columns to _m2, _m3\n",
    "        #   - use the forecasted data from the previous day for mean_1m_temp_degC_m1 and mean_0_5m_temp_degC_m1\n",
    "        #   - use the test data for all other columns (flow, chipmunk, north_fork)\n",
    "\n",
    "        else:\n",
    "            # remove the noon met data\n",
    "            obs = obs.drop(columns=[\"noon_air_temp\", \"noon_ave_wind\", \"noon_solar_rad\"])\n",
    "            # grab the forecast data for the offset date\n",
    "            fore_select = fore[fore[\"offset\"] == d].copy()\n",
    "            # join fore_select with obs, drop offset columns, and use the number column as index\n",
    "            obs_fore = obs.join(fore_select.set_index(\"date\"), on=\"date\")\n",
    "            obs_fore = obs_fore.drop(columns=[\"offset\"])\n",
    "            obs_fore = obs_fore.set_index(\"number\")\n",
    "            # remove all columns ending in _m7\n",
    "            obs_fore = obs_fore.loc[:, ~obs_fore.columns.str.endswith(\"_m7\")]\n",
    "            # rename all columns ending in _m1, ..., _m6 to _m2, ..., _m7\n",
    "            obs_fore.columns = obs_fore.columns.str.replace(\"_m1\", \"_m2\")\n",
    "            obs_fore.columns = obs_fore.columns.str.replace(\"_m2\", \"_m3\")\n",
    "            obs_fore.columns = obs_fore.columns.str.replace(\"_m3\", \"_m4\")\n",
    "            obs_fore.columns = obs_fore.columns.str.replace(\"_m4\", \"_m5\")\n",
    "            obs_fore.columns = obs_fore.columns.str.replace(\"_m5\", \"_m6\")\n",
    "            obs_fore.columns = obs_fore.columns.str.replace(\"_m6\", \"_m7\")\n",
    "            # drop the _m3 column of the mean_1m_temp_degC and mean_0_5m_temp_degC (this is now named _m4 from the previous step)\n",
    "            obs_fore = obs_fore.drop(columns=[\"mean_1m_temp_degC_m4\", \"mean_0_5m_temp_degC_m4\"])\n",
    "            # use the forecasted data from the previous day for mean_1m_temp_degC_m1 and mean_0_5m_temp_degC_m1\n",
    "            obs_fore[\"mean_1m_temp_degC_m1\"] = all_forecasts[all_forecasts[\"date\"] == forecast_date - pd.DateOffset(days=1)][\"mean_1m_temp_degC\"]\n",
    "        \n",
    "            # duplicate this forecast data to match with the outputs from the previous day\n",
    "            \n",
    "            # grab the forecast data for the offset date\n",
    "            fore_select = fore[fore[\"offset\"] == d].copy()\n",
    "            # join fore_select with obs, drop offset columns, and use the number column as index\n",
    "            obs_fore = obs.join(fore_select.set_index(\"date\"), on=\"date\")\n",
    "            obs_fore = obs_fore.drop(columns=[\"offset\"])\n",
    "            obs_fore = obs_fore.set_index(\"number\")\n",
    "            # now reorganize the columns to match the input columns\n",
    "            obs_fore = obs_fore[forecast_cols]all_forecasts\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# create an empty dataframe to store the forecast data\n",
    "# forecasted_data = pd.DataFrame(columns=[\"date\", ])\n",
    "\n",
    "make_forecast(\"2022-08-20\", 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'mean_1m_temp_degC', 'mean_0_5m_temp_degC',\n",
       "       'mean_1m_temp_degC_m1', 'mean_0_5m_temp_degC_m1',\n",
       "       'mean_1m_temp_degC_m2', 'mean_0_5m_temp_degC_m2',\n",
       "       'mean_1m_temp_degC_m3', 'mean_0_5m_temp_degC_m3', 'pump_q_m1',\n",
       "       'pump_q_m2', 'sum_pump_q_p2', 'max_pump_q_p2', 'sum_pump_q_p7',\n",
       "       'max_pump_q_p7', 'ave_chip_q_m1', 'max_chip_q_m1', 'ave_chip_q_m2',\n",
       "       'max_chip_q_m2', 'mean_chip_q_p7', 'max_chip_q_p7', 'noon_air_temp_m1',\n",
       "       'noon_air_temp_m2', 'noon_air_temp_m3', 'noon_air_temp_m4',\n",
       "       'noon_air_temp_m5', 'noon_air_temp_m6', 'noon_air_temp_m7',\n",
       "       'noon_air_temp', 'noon_ave_wind_m1', 'noon_ave_wind_m2',\n",
       "       'noon_ave_wind_m3', 'noon_ave_wind_m4', 'noon_ave_wind_m5',\n",
       "       'noon_ave_wind_m6', 'noon_ave_wind_m7', 'noon_ave_wind',\n",
       "       'noon_solar_rad_m1', 'noon_solar_rad_m2', 'noon_solar_rad_m3',\n",
       "       'noon_solar_rad_m4', 'noon_solar_rad_m5', 'noon_solar_rad_m6',\n",
       "       'noon_solar_rad_m7', 'noon_solar_rad', 'min_chip_q_m1', 'min_chip_q_m2',\n",
       "       'min_chip_q_p7', 'NF_q_m1', 'NF_q_m2', 'mean_NF_q_p7', 'max_NF_q_p7'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_NW",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
