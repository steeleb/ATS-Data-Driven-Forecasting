{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script walks through a forecast for SMR using the NN-operational model developed in the NASA-NW repo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#high level modules\n",
    "import os\n",
    "import imp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom modules\n",
    "this_dir = \"/Users/steeleb/Documents/GitHub/ats-data-driven-forecasting/NN-operational/arNN/\"\n",
    "\n",
    "imp.load_source(\"universals\", os.path.join(this_dir, \"universal_functions.py\"))\n",
    "from universals import load_pickle_file, calculate_vals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"/Users/steeleb/Documents/GitHub/ats-data-driven-forecasting/data/NN_train_val_test/SMR_forecast/models/leaky_basic_5/\"\n",
    "\n",
    "model_1 = load_pickle_file(\"model_1.pkl\", model_dir)\n",
    "model_2 = load_pickle_file(\"model_2.pkl\", model_dir)\n",
    "model_3 = load_pickle_file(\"model_3.pkl\", model_dir)\n",
    "model_4 = load_pickle_file(\"model_4.pkl\", model_dir)\n",
    "model_5 = load_pickle_file(\"model_5.pkl\", model_dir)\n",
    "model_6 = load_pickle_file(\"model_6.pkl\", model_dir)\n",
    "model_7 = load_pickle_file(\"model_7.pkl\", model_dir)\n",
    "model_8 = load_pickle_file(\"model_8.pkl\", model_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/Users/steeleb/Documents/GitHub/ats-data-driven-forecasting/data/NN_train_val_test/SMR_forecast/\"\n",
    "\n",
    "test = pd.read_csv(os.path.join(data_dir, \"t2022_standardized_v2024-10-28.csv\"))\n",
    "forecast = pd.read_csv(os.path.join(data_dir, \"t2022_forecast_std_v2024-10-28.csv\"))\n",
    "\n",
    "test[\"date\"] = pd.to_datetime(test[\"date\"])\n",
    "forecast[\"date\"] = pd.to_datetime(forecast[\"date\"])\n",
    "forecast[\"forecast_date\"] = pd.to_datetime(forecast[\"forecast_date\"])\n",
    "\n",
    "# we need the test columns to be the same as the forecast columns at the end of this, so grab the names for now\n",
    "forecast_cols = test.columns\n",
    "\n",
    "# and let's drop the observed temp data from the forecast columns, too\n",
    "forecast_cols_less = forecast_cols.drop([\"mean_1m_temp_degC\", \"mean_0_5m_temp_degC\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create function to roll out forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_forecast(date, n_days):\n",
    "    \n",
    "    print(date)\n",
    "    date = pd.to_datetime(date)\n",
    "    \n",
    "    # get the forecast data from a specific date\n",
    "    fore = forecast[forecast[\"forecast_date\"] == date].copy()\n",
    "    # earliest date is noon met for forecast. Calculatet the differencein dates and add as a column called \"offset\"\n",
    "    fore[\"offset\"] = (fore[\"date\"] - fore[\"forecast_date\"]).dt.days\n",
    "    # remove the date column and rename forecast_date to date\n",
    "    fore = fore.drop(columns=[\"forecast_date\"])\n",
    "    \n",
    "    # we'll run a forecast for each day, since the following day's forecast will be based on the previous day's forecast\n",
    "    for d in range(n_days):\n",
    "        # Setup for the iteration\n",
    "        print(\"Forecasting day: \", d+1)\n",
    "        # set the forecast date\n",
    "        forecast_date = pd.to_datetime(date) + pd.DateOffset(days=d)\n",
    "        obs = test[test[\"date\"] == forecast_date].copy()\n",
    "        \n",
    "        # the first day will be a bit different from subsequent days\n",
    "        if d == 0:\n",
    "            # remove the noon met data\n",
    "            obs = obs.drop(columns=[\"noon_air_temp\", \"noon_ave_wind\", \"noon_solar_rad\"])\n",
    "            # grab the forecast data for the offset date\n",
    "            fore_select = fore[fore[\"offset\"] == d].copy()\n",
    "            # join fore_select with obs, drop offset columns, and use the number column as index\n",
    "            obs_fore = obs.join(fore_select.set_index(\"date\"), on=\"date\")\n",
    "            obs_fore = obs_fore.drop(columns=[\"offset\"])\n",
    "            obs_fore = obs_fore.set_index(\"number\")\n",
    "            # now reorganize the columns to match the input columns\n",
    "            obs_fore = obs_fore[forecast_cols]\n",
    "            \n",
    "            # preprocess the data into labels and features\n",
    "            features = obs_fore.drop(columns = [\"date\", \"mean_1m_temp_degC\", \"mean_0_5m_temp_degC\"])\n",
    "            \n",
    "            # make the forecast for each perturbation\n",
    "            pred_1 = model_1.predict(features)\n",
    "            pred_2 = model_2.predict(features)\n",
    "            pred_3 = model_3.predict(features)\n",
    "            pred_4 = model_4.predict(features)\n",
    "            pred_5 = model_5.predict(features)\n",
    "            pred_6 = model_6.predict(features)\n",
    "            pred_7 = model_7.predict(features)\n",
    "            pred_8 = model_8.predict(features)\n",
    "\n",
    "            # and now we need to create the dataframe for the next iteration\n",
    "            # first, create a dataframe with the forecast data\n",
    "            for i, pred in enumerate([pred_1, pred_2, pred_3, pred_4, pred_5, pred_6, pred_7, pred_8], start=1):\n",
    "                forecasted_temp = pd.DataFrame(columns=['date', 'perturbation', 'model', 'mean_1m_temp_degC', 'mean_0_5m_temp_degC'])\n",
    "                forecasted_temp[\"perturbation\"] = obs_fore.index\n",
    "                forecasted_temp['model'] = i\n",
    "                forecasted_temp[\"mean_1m_temp_degC\"] = [p[0] for p in pred]\n",
    "                forecasted_temp[\"mean_0_5m_temp_degC\"] = [p[1] for p in pred]\n",
    "                forecasted_temp[\"date\"] = forecast_date\n",
    "                \n",
    "                # Append to the main dataframe (or create it if it doesn't exist)\n",
    "                if 'all_forecasts' in locals():\n",
    "                    all_forecasts = pd.concat([all_forecasts, forecasted_temp])\n",
    "                else:\n",
    "                    all_forecasts = forecasted_temp.copy()\n",
    "            \n",
    "            # for all other days, we need to:\n",
    "            #   - use the forecast met data for d-offset for noon met data\n",
    "            #   - drop the _m7 met data columns\n",
    "            #   - rename the _m1, ..., _m6 columns to _m2, ..., _m7 for the met data columns\n",
    "            #   - drop the _m3 column of the mean_1m_temp_degC and mean_0_5m_temp_degC\n",
    "            #   - rename the _m1, _m2, _m3 columns to _m2, _m3\n",
    "            #   - use the forecasted data from the previous day for mean_1m_temp_degC_m1 and mean_0_5m_temp_degC_m1\n",
    "            #   - use the test data for all other columns (flow, chipmunk, north_fork)\n",
    "        \n",
    "        elif d == 1:\n",
    "            # remove the noon met data and the observed temperature data from yesterday and today (we'll replaced these with forecasted data)\n",
    "            obs = obs.drop(columns=[\"noon_air_temp\", \"noon_ave_wind\", \"noon_solar_rad\",\n",
    "                                    \"mean_1m_temp_degC\", \"mean_0_5m_temp_degC\",\n",
    "                                    \"mean_1m_temp_degC_m1\", \"mean_0_5m_temp_degC_m1\"])\n",
    "            \n",
    "            # grab the forecast data for the offset date the merge with the observed data\n",
    "            fore_select = fore[fore[\"offset\"] == d].copy()\n",
    "            fore_select = fore_select.rename(columns={\"number\": \"perturbation\"})\n",
    "            \n",
    "            # join obs (one row) with fore_select (many rows) on the date column\n",
    "            obs_fore = obs.join(fore_select.set_index(\"date\"), on=\"date\")\n",
    "            obs_fore = obs_fore.drop(columns=[\"offset\"])\n",
    "            # we'll join the forecasted data using the perturbation column and the date, so set those as index\n",
    "            obs_fore = obs_fore.set_index([\"date\", \"perturbation\"])\n",
    "\n",
    "            # join the observational forecast data with the forecasted data from the previous day by date and perturbation\n",
    "            to_forecast = all_forecasts.copy()\n",
    "            to_forecast = to_forecast[to_forecast[\"date\"] == forecast_date - pd.DateOffset(days=1)]\n",
    "            to_forecast[\"date\"] = pd.to_datetime(to_forecast[\"date\"]) + pd.DateOffset(days=1)\n",
    "            to_forecast.columns = to_forecast.columns.str.replace(\"degC\", \"degC_m1\")\n",
    "            to_forecast = to_forecast.set_index([\"date\", \"perturbation\"])\n",
    "            to_forecast = to_forecast.join(obs_fore, on=[\"date\", \"perturbation\"])\n",
    "\n",
    "            # now we need to reorganize the columns to match the input columns, plus the model and peturbation colums\n",
    "            # first, move the date and perturbation from the index to columns\n",
    "            to_forecast = to_forecast.reset_index()\n",
    "            # now change model and perturbation to the index\n",
    "            to_forecast = to_forecast.set_index([\"model\", \"perturbation\"])\n",
    "            # and now reorganize the columns to match the input columns\n",
    "            to_forecast = to_forecast[forecast_cols_less]\n",
    "\n",
    "            # and now we need to preprocess the data into features\n",
    "            forecast_features = to_forecast.drop(columns = \"date\")\n",
    "\n",
    "            # for each model, make the forecast and store the results\n",
    "            # make a dataframe to store the forecasted data\n",
    "            forecasted_temp = pd.DataFrame(columns=['date', 'perturbation', 'model', 'mean_1m_temp_degC', 'mean_0_5m_temp_degC'])\n",
    "            \n",
    "            # loop through the models\n",
    "            for m in range(1, 9):\n",
    "                # filter the forecast features for the model and drop the model column\n",
    "                model_forecast_features = forecast_features[forecast_features.index.get_level_values(0) == m].copy()\n",
    "                # make the forecast for each perturbation\n",
    "                pred = eval(f\"model_{m}\").predict(model_forecast_features)\n",
    "                forecasted_temp[\"perturbation\"] = model_forecast_features.index.get_level_values(1)\n",
    "                forecasted_temp['model'] = m\n",
    "                forecasted_temp[\"mean_1m_temp_degC\"] = [p[0] for p in pred]\n",
    "                forecasted_temp[\"mean_0_5m_temp_degC\"] = [p[1] for p in pred]\n",
    "                forecasted_temp[\"date\"] = forecast_date\n",
    "\n",
    "                # Append to a dataframe (or create it if it doesn't exist)\n",
    "                if 'forecasted_date' in locals():\n",
    "                    forecasted_date = pd.concat([forecasted_date, forecasted_temp])\n",
    "                else:\n",
    "                    forecasted_date = forecasted_temp.copy()\n",
    "            \n",
    "            # Append to the main dataframe\n",
    "            all_forecasts = pd.concat([all_forecasts, forecasted_date])\n",
    "        \n",
    "        elif d == 2:\n",
    "            # remove the noon met data and the observed temperature data from yesterday and today (we'll replaced these with forecasted data)\n",
    "            obs = obs.drop(columns=[\"noon_air_temp\", \"noon_ave_wind\", \"noon_solar_rad\",\n",
    "                                    \"mean_1m_temp_degC\", \"mean_0_5m_temp_degC\",\n",
    "                                    \"mean_1m_temp_degC_m1\", \"mean_0_5m_temp_degC_m1\", \n",
    "                                    \"mean_1m_temp_degC_m2\", \"mean_0_5m_temp_degC_m2\"])\n",
    "            \n",
    "            # grab the forecast data for the offset date the merge with the observed data\n",
    "            fore_select = fore[fore[\"offset\"] == d].copy()\n",
    "            fore_select = fore_select.rename(columns={\"number\": \"perturbation\"})\n",
    "            \n",
    "            # join obs (one row) with fore_select (many rows) on the date column\n",
    "            obs_fore = obs.join(fore_select.set_index(\"date\"), on=\"date\")\n",
    "            obs_fore = obs_fore.drop(columns=[\"offset\"])\n",
    "            # we'll join the forecasted data using the perturbation column and the date, so set those as index\n",
    "            obs_fore = obs_fore.set_index([\"date\", \"perturbation\"])\n",
    "\n",
    "            # add yesterday's temp forecast to the observational forecast data by date and perturbation\n",
    "            m1_forecast = all_forecasts.copy()\n",
    "            m1_forecast = m1_forecast[m1_forecast[\"date\"] == forecast_date - pd.DateOffset(days=1)]\n",
    "            m1_forecast[\"date\"] = pd.to_datetime(m1_forecast[\"date\"]) + pd.DateOffset(days=1)\n",
    "            m1_forecast.columns = m1_forecast.columns.str.replace(\"degC\", \"degC_m1\")\n",
    "            m1_forecast = m1_forecast.set_index([\"date\", \"perturbation\"])\n",
    "            m1_forecast = m1_forecast.join(obs_fore, on=[\"date\", \"perturbation\"])\n",
    "            m1_forecast = m1_forecast.reset_index()\n",
    "            m1_forecast = m1_forecast.set_index([\"date\", \"perturbation\", \"model\"])\n",
    "\n",
    "            # and two days prior\n",
    "            to_forecast = all_forecasts.copy()\n",
    "            to_forecast = to_forecast[to_forecast[\"date\"] == forecast_date - pd.DateOffset(days=2)]\n",
    "            to_forecast[\"date\"] = pd.to_datetime(to_forecast[\"date\"]) + pd.DateOffset(days=2)\n",
    "            to_forecast.columns = to_forecast.columns.str.replace(\"degC\", \"degC_m2\")\n",
    "            to_forecast = to_forecast.set_index([\"date\", \"perturbation\", \"model\"])\n",
    "            to_forecast = to_forecast.join(m1_forecast, on=[\"date\", \"perturbation\", \"model\"])\n",
    "\n",
    "            # now we need to reorganize the columns to match the input columns, plus the model and peturbation colums\n",
    "            # first, move the date and perturbation from the index to columns\n",
    "            to_forecast = to_forecast.reset_index()\n",
    "            # now change model and perturbation to the index\n",
    "            to_forecast = to_forecast.set_index([\"model\", \"perturbation\"])\n",
    "            # and now reorganize the columns to match the input columns\n",
    "            to_forecast = to_forecast[forecast_cols_less]\n",
    "\n",
    "            # and now we need to preprocess the data into features\n",
    "            forecast_features = to_forecast.drop(columns = \"date\")\n",
    "\n",
    "            # for each model, make the forecast and store the results\n",
    "            # make a dataframe to store the forecasted data\n",
    "            forecasted_temp = pd.DataFrame(columns=['date', 'perturbation', 'model', 'mean_1m_temp_degC', 'mean_0_5m_temp_degC'])\n",
    "            \n",
    "            # loop through the models\n",
    "            for m in range(1, 9):\n",
    "                # filter the forecast features for the model and drop the model column\n",
    "                model_forecast_features = forecast_features[forecast_features.index.get_level_values(0) == m].copy()\n",
    "                # make the forecast for each perturbation\n",
    "                pred = eval(f\"model_{m}\").predict(model_forecast_features)\n",
    "                forecasted_temp[\"perturbation\"] = model_forecast_features.index.get_level_values(1)\n",
    "                forecasted_temp['model'] = m\n",
    "                forecasted_temp[\"mean_1m_temp_degC\"] = [p[0] for p in pred]\n",
    "                forecasted_temp[\"mean_0_5m_temp_degC\"] = [p[1] for p in pred]\n",
    "                forecasted_temp[\"date\"] = forecast_date\n",
    "\n",
    "                # Append to a dataframe (or create it if it doesn't exist)\n",
    "                if 'forecasted_date' in locals():\n",
    "                    forecasted_date = pd.concat([forecasted_date, forecasted_temp])\n",
    "                else:\n",
    "                    forecasted_date = forecasted_temp.copy()\n",
    "            \n",
    "            # Append to the main dataframe\n",
    "            all_forecasts = pd.concat([all_forecasts, forecasted_date])\n",
    "\n",
    "        elif d > 2 & d < n_days:\n",
    "            \n",
    "            # remove the noon met data and the observed temperature data from yesterday and today (we'll replaced these with forecasted data)\n",
    "            obs = obs.drop(columns=[\"noon_air_temp\", \"noon_ave_wind\", \"noon_solar_rad\",\n",
    "                                    \"mean_1m_temp_degC\", \"mean_0_5m_temp_degC\",\n",
    "                                    \"mean_1m_temp_degC_m1\", \"mean_0_5m_temp_degC_m1\", \n",
    "                                    \"mean_1m_temp_degC_m2\", \"mean_0_5m_temp_degC_m2\",\n",
    "                                    \"mean_1m_temp_degC_m3\", \"mean_0_5m_temp_degC_m3\"])\n",
    "            \n",
    "            # grab the forecast data for the offset date the merge with the observed data\n",
    "            fore_select = fore[fore[\"offset\"] == d].copy()\n",
    "            fore_select = fore_select.rename(columns={\"number\": \"perturbation\"})\n",
    "            \n",
    "            # join obs (one row) with fore_select (many rows) on the date column\n",
    "            obs_fore = obs.join(fore_select.set_index(\"date\"), on=\"date\")\n",
    "            obs_fore = obs_fore.drop(columns=[\"offset\"])\n",
    "            # we'll join the forecasted data using the perturbation column and the date, so set those as index\n",
    "            obs_fore = obs_fore.set_index([\"date\", \"perturbation\"])\n",
    "\n",
    "            # add yesterday's temp forecast to the observational forecast data by date and perturbation\n",
    "            m1_forecast = all_forecasts.copy()\n",
    "            m1_forecast = m1_forecast[m1_forecast[\"date\"] == forecast_date - pd.DateOffset(days=1)]\n",
    "            m1_forecast[\"date\"] = pd.to_datetime(m1_forecast[\"date\"]) + pd.DateOffset(days=1)\n",
    "            m1_forecast.columns = m1_forecast.columns.str.replace(\"degC\", \"degC_m1\")\n",
    "            m1_forecast = m1_forecast.set_index([\"date\", \"perturbation\"])\n",
    "            m1_forecast = m1_forecast.join(obs_fore, on=[\"date\", \"perturbation\"])\n",
    "            m1_forecast = m1_forecast.reset_index()\n",
    "            m1_forecast = m1_forecast.set_index([\"date\", \"perturbation\", \"model\"])\n",
    "\n",
    "            # and two days prior\n",
    "            m2_forecast = all_forecasts.copy()\n",
    "            m2_forecast = m2_forecast[m2_forecast[\"date\"] == forecast_date - pd.DateOffset(days=2)]\n",
    "            m2_forecast[\"date\"] = pd.to_datetime(m2_forecast[\"date\"]) + pd.DateOffset(days=2)\n",
    "            m2_forecast.columns = m2_forecast.columns.str.replace(\"degC\", \"degC_m2\")\n",
    "            m2_forecast = m2_forecast.set_index([\"date\", \"perturbation\", \"model\"])\n",
    "            m2_forecast = m2_forecast.join(m1_forecast, on=[\"date\", \"perturbation\", \"model\"])\n",
    "\n",
    "            # and three days prior\n",
    "            to_forecast = all_forecasts.copy()\n",
    "            to_forecast = to_forecast[to_forecast[\"date\"] == forecast_date - pd.DateOffset(days=3)]\n",
    "            to_forecast[\"date\"] = pd.to_datetime(to_forecast[\"date\"]) + pd.DateOffset(days=3)\n",
    "            to_forecast.columns = to_forecast.columns.str.replace(\"degC\", \"degC_m3\")\n",
    "            to_forecast = to_forecast.set_index([\"date\", \"perturbation\", \"model\"])\n",
    "            to_forecast = to_forecast.join(m2_forecast, on=[\"date\", \"perturbation\", \"model\"])\n",
    "\n",
    "            # now we need to reorganize the columns to match the input columns, plus the model and peturbation colums\n",
    "            # first, move the date and perturbation from the index to columns\n",
    "            to_forecast = to_forecast.reset_index()\n",
    "            # now change model and perturbation to the index\n",
    "            to_forecast = to_forecast.set_index([\"model\", \"perturbation\"])\n",
    "            # and now reorganize the columns to match the input columns\n",
    "            to_forecast = to_forecast[forecast_cols_less]\n",
    "\n",
    "            # and now we need to preprocess the data into features\n",
    "            forecast_features = to_forecast.drop(columns = \"date\")\n",
    "\n",
    "            # for each model, make the forecast and store the results\n",
    "            # make a dataframe to store the forecasted data\n",
    "            forecasted_temp = pd.DataFrame(columns=['date', 'perturbation', 'model', 'mean_1m_temp_degC', 'mean_0_5m_temp_degC'])\n",
    "            \n",
    "            # loop through the models\n",
    "            for m in range(1, 9):\n",
    "                # filter the forecast features for the model and drop the model column\n",
    "                model_forecast_features = forecast_features[forecast_features.index.get_level_values(0) == m].copy()\n",
    "                # make the forecast for each perturbation\n",
    "                pred = eval(f\"model_{m}\").predict(model_forecast_features)\n",
    "                forecasted_temp[\"perturbation\"] = model_forecast_features.index.get_level_values(1)\n",
    "                forecasted_temp['model'] = m\n",
    "                forecasted_temp[\"mean_1m_temp_degC\"] = [p[0] for p in pred]\n",
    "                forecasted_temp[\"mean_0_5m_temp_degC\"] = [p[1] for p in pred]\n",
    "                forecasted_temp[\"date\"] = forecast_date\n",
    "\n",
    "                # Append to a dataframe (or create it if it doesn't exist)\n",
    "                if 'forecasted_date' in locals():\n",
    "                    forecasted_date = pd.concat([forecasted_date, forecasted_temp])\n",
    "                else:\n",
    "                    forecasted_date = forecasted_temp.copy()\n",
    "            \n",
    "            # Append to the main dataframe\n",
    "            all_forecasts = pd.concat([all_forecasts, forecasted_date])\n",
    "    \n",
    "    return all_forecasts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a few forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-07\n",
      "Forecasting day:  1\n",
      "Forecasting day:  2\n",
      "Forecasting day:  3\n",
      "Forecasting day:  4\n",
      "Forecasting day:  5\n",
      "Forecasting day:  6\n",
      "Forecasting day:  7\n",
      "2022-08-20\n",
      "Forecasting day:  1\n",
      "Forecasting day:  2\n",
      "Forecasting day:  3\n",
      "Forecasting day:  4\n",
      "Forecasting day:  5\n",
      "Forecasting day:  6\n",
      "Forecasting day:  7\n",
      "2022-09-11\n",
      "Forecasting day:  1\n",
      "Forecasting day:  2\n",
      "Forecasting day:  3\n",
      "Forecasting day:  4\n",
      "Forecasting day:  5\n",
      "Forecasting day:  6\n",
      "Forecasting day:  7\n"
     ]
    }
   ],
   "source": [
    "jul07_seven_day = make_forecast(\"2022-07-07\", 7)\n",
    "aug20_seven_day = make_forecast(\"2022-08-20\", 7)\n",
    "sept11_seven_day = make_forecast(\"2022-09-11\", 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate actual values from the forecasted data\n",
    "\n",
    "I'm not sure why this creates dupes, but it does, i'll have to figure that out later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicates\n",
    "jul07_seven_day = jul07_seven_day.drop_duplicates()\n",
    "aug20_seven_day = aug20_seven_day.drop_duplicates()\n",
    "sept11_seven_day = sept11_seven_day.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_std = pd.read_csv(os.path.join(data_dir, \"mean_std_train_val_t2022_v2024-10-28.csv\"))\n",
    "mean_std = mean_std.set_index(\"Unnamed: 0\")\n",
    "\n",
    "jul07_seven_day[\"mean_1m_temp_degC\"] = calculate_vals(jul07_seven_day[\"mean_1m_temp_degC\"], mean_std.loc[\"mean_1m_temp_degC\", \"mean\"], mean_std.loc[\"mean_1m_temp_degC\", \"std\"])\n",
    "jul07_seven_day[\"mean_0_5m_temp_degC\"] = calculate_vals(jul07_seven_day[\"mean_0_5m_temp_degC\"], mean_std.loc[\"mean_0_5m_temp_degC\", \"mean\"], mean_std.loc[\"mean_0_5m_temp_degC\", \"std\"])\n",
    "\n",
    "aug20_seven_day[\"mean_1m_temp_degC\"] = calculate_vals(aug20_seven_day[\"mean_1m_temp_degC\"], mean_std.loc[\"mean_1m_temp_degC\", \"mean\"], mean_std.loc[\"mean_1m_temp_degC\", \"std\"])\n",
    "aug20_seven_day[\"mean_0_5m_temp_degC\"] = calculate_vals(aug20_seven_day[\"mean_0_5m_temp_degC\"], mean_std.loc[\"mean_0_5m_temp_degC\", \"mean\"], mean_std.loc[\"mean_0_5m_temp_degC\", \"std\"])\n",
    "\n",
    "sept11_seven_day[\"mean_1m_temp_degC\"] = calculate_vals(sept11_seven_day[\"mean_1m_temp_degC\"], mean_std.loc[\"mean_1m_temp_degC\", \"mean\"], mean_std.loc[\"mean_1m_temp_degC\", \"std\"])\n",
    "sept11_seven_day[\"mean_0_5m_temp_degC\"] = calculate_vals(sept11_seven_day[\"mean_0_5m_temp_degC\"], mean_std.loc[\"mean_0_5m_temp_degC\", \"mean\"], mean_std.loc[\"mean_0_5m_temp_degC\", \"std\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save a csv of those forecasts\n",
    "jul07_seven_day.to_csv(\"~/Documents/GitHub/ats-data-driven-forecasting/run-operational/output/jul07_seven_day.csv\", index=False)\n",
    "aug20_seven_day.to_csv(\"~/Documents/GitHub/ats-data-driven-forecasting/run-operational/output/aug20_seven_day.csv\", index=False)\n",
    "sept11_seven_day.to_csv(\"~/Documents/GitHub/ats-data-driven-forecasting/run-operational/output/sept11_seven_day.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_NW",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
