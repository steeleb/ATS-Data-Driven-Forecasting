{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "\n",
    "This script creates some quick visualizations of the model output and performance to see if the model is overfit or underfit. We look at the training histories, predicted/observed plots, and timeseries plots to see what the data look like in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#high level modules\n",
    "import os\n",
    "import imp\n",
    "import pandas as pd\n",
    "\n",
    "# ml/ai modules\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "# import pydot\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import custom modules\n",
    "this_dir = \"/Users/steeleb/Documents/GitHub/NASA-NW/modeling/temperature/arNN_fewer2/\"\n",
    "imp.load_source(\"universals\", os.path.join(this_dir, \"universal_functions.py\"))\n",
    "from universals import load_pickle_file, twotemp_labels_features, predict_2_values, print_error_metrics\n",
    "imp.load_source(\"vis\", os.path.join(this_dir, \"vis_functions.py\"))\n",
    "from vis import create_scatter_plot, ts_plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Loss in Training and Validation\n",
    "\n",
    "Load in training histories models from pickle files craeted in `_leaky_basic_5_vis_t2023.ipynb` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model directory path\n",
    "model_dir = '/Users/steeleb/Documents/GitHub/NASA-NW/data/NN_train_val_test/SMR_autoNN_reduce_2/models/leaky_basic_5_t2023/'\n",
    "\n",
    "histories = [f for f in os.listdir(model_dir) if 'history' in f]\n",
    "\n",
    "history_1 = load_pickle_file(histories[0], model_dir)\n",
    "history_2 = load_pickle_file(histories[1], model_dir)\n",
    "history_3 = load_pickle_file(histories[2], model_dir)\n",
    "history_4 = load_pickle_file(histories[3], model_dir)\n",
    "history_5 = load_pickle_file(histories[4], model_dir)\n",
    "history_6 = load_pickle_file(histories[5], model_dir)\n",
    "history_7 = load_pickle_file(histories[6], model_dir)\n",
    "history_8 = load_pickle_file(histories[7], model_dir)\n",
    "history_9 = load_pickle_file(histories[8], model_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And plot the loss in training and validation datasets to see if the model is overfitting or underfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_1.history['loss'])\n",
    "plt.plot(history_1.history['val_loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.title('Model 1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_2.history['loss'])\n",
    "plt.plot(history_2.history['val_loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.title('Model 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_3.history['loss'])\n",
    "plt.plot(history_3.history['val_loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.title('Model 3')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_4.history['loss'])\n",
    "plt.plot(history_4.history['val_loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.title('Model 4')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_5.history['loss'])\n",
    "plt.plot(history_5.history['val_loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.title('Model 5')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_6.history['loss'])\n",
    "plt.plot(history_6.history['val_loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.title('Model 6')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_7.history['loss'])\n",
    "plt.plot(history_7.history['val_loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.title('Model 7')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_8.history['loss'])\n",
    "plt.plot(history_8.history['val_loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.title('Model 8')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_9.history['loss'])\n",
    "plt.plot(history_9.history['val_loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.title('Model 9')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Predicted vs Observed\n",
    "\n",
    "In order to do this, we need to load in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/Users/steeleb/Documents/GitHub/NASA-NW/data/NN_train_val_test/SMR_autoNN_reduce_2/\"\n",
    "\n",
    "all_files = pd.Series(os.listdir(data_dir))\n",
    "t2023 = all_files[all_files.str.contains('t2023')]\n",
    "t2023_val = t2023[t2023.str.contains('validation')]\n",
    "t2023_train = t2023[t2023.str.contains('training')]\n",
    "\n",
    "# these files end up in no particular order, so we need to sort them\n",
    "t2023_val = t2023_val.sort_values()\n",
    "t2023_train = t2023_train.sort_values()\n",
    "\n",
    "def load_data(file):\n",
    "    return pd.read_csv(os.path.join(data_dir, file), sep=',')\n",
    "\n",
    "val1 = load_data(t2023_val.values[0])\n",
    "train1 = load_data(t2023_train.values[0])\n",
    "\n",
    "val2 = load_data(t2023_val.values[1])\n",
    "train2 = load_data(t2023_train.values[1])\n",
    "\n",
    "val3 = load_data(t2023_val.values[2])\n",
    "train3 = load_data(t2023_train.values[2])\n",
    "\n",
    "val4 = load_data(t2023_val.values[3])\n",
    "train4 = load_data(t2023_train.values[3])\n",
    "\n",
    "val5 = load_data(t2023_val.values[5])\n",
    "train5 = load_data(t2023_train.values[5])\n",
    "\n",
    "val6 = load_data(t2023_val.values[5])\n",
    "train6 = load_data(t2023_train.values[5])\n",
    "\n",
    "val7 = load_data(t2023_val.values[6])\n",
    "train7 = load_data(t2023_train.values[6])\n",
    "\n",
    "val8 = load_data(t2023_val.values[7])\n",
    "train8 = load_data(t2023_train.values[7])\n",
    "\n",
    "val9 = load_data(t2023_val.values[8])\n",
    "train9 = load_data(t2023_train.values[8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then create the feature and lables for training and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "features1, labels_1, val_features1, val_labels_1 = twotemp_labels_features(train1, val1)\n",
    "features2, labels_2, val_features2, val_labels_2 = twotemp_labels_features(train2, val2)\n",
    "features3, labels_3, val_features3, val_labels_3 = twotemp_labels_features(train3, val3)\n",
    "features4, labels_4, val_features4, val_labels_4 = twotemp_labels_features(train4, val4)\n",
    "features5, labels_5, val_features5, val_labels_5 = twotemp_labels_features(train5, val5)\n",
    "features6, labels_6, val_features6, val_labels_6 = twotemp_labels_features(train6, val6)\n",
    "features7, labels_7, val_features7, val_labels_7 = twotemp_labels_features(train7, val7)\n",
    "features8, labels_8, val_features8, val_labels_8 = twotemp_labels_features(train8, val8)\n",
    "features9, labels_9, val_features9, val_labels_9 = twotemp_labels_features(train9, val9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And load the pickle files from the `_leaky_basic_5_model_t2023.ipynb` notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [f for f in os.listdir(model_dir) if 'history' not in f]\n",
    "\n",
    "model_1 = load_pickle_file(models[0], model_dir)\n",
    "model_2 = load_pickle_file(models[1], model_dir)\n",
    "model_3 = load_pickle_file(models[2], model_dir)\n",
    "model_4 = load_pickle_file(models[3], model_dir)\n",
    "model_5 = load_pickle_file(models[4], model_dir)\n",
    "model_6 = load_pickle_file(models[5], model_dir)\n",
    "model_7 = load_pickle_file(models[6], model_dir)\n",
    "model_8 = load_pickle_file(models[7], model_dir)\n",
    "model_9 = load_pickle_file(models[8], model_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we need to transform the label data back to the original scale. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = pd.read_csv(os.path.join(data_dir, \"mean_std_train_val_t2023_v2024-05-21.csv\"), sep=',')\n",
    "transform = transform.rename(columns={\"Unnamed: 0\": \"feature\"}).set_index(\"feature\")\n",
    "\n",
    "\n",
    "t_mean_1m = transform['mean'].get('mean_1m_temp_degC')\n",
    "t_std_1m = transform['std'].get('mean_1m_temp_degC')\n",
    "\n",
    "t_mean_05m = transform['mean'].get('mean_0_5m_temp_degC')\n",
    "t_std_05m = transform['std'].get('mean_0_5m_temp_degC')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll u se the model to predict the labels for the training and validation datasets using the mean and standard deviations from the preprocessing routine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call predict_values for each dataset\n",
    "p_train_1m_1, p_train_05m_1, act_train_1m_1, act_train_05m_1, p_val_1m_1, p_val_05m_1, act_val_1m_1, act_val_05m_1 = predict_2_values(model_1, features1, val_features1, labels_1, val_labels_1, t_mean_1m, t_mean_05m, t_std_1m, t_std_05m)\n",
    "p_train_1m_2, p_train_05m_2, act_train_1m_2, act_train_05m_2, p_val_1m_2, p_val_05m_2, act_val_1m_2, act_val_05m_2 = predict_2_values(model_2, features2, val_features2, labels_2, val_labels_2, t_mean_1m, t_mean_05m, t_std_1m, t_std_05m)\n",
    "p_train_1m_3, p_train_05m_3, act_train_1m_3, act_train_05m_3, p_val_1m_3, p_val_05m_3, act_val_1m_3, act_val_05m_3 = predict_2_values(model_3, features3, val_features3, labels_3, val_labels_3, t_mean_1m, t_mean_05m, t_std_1m, t_std_05m)\n",
    "p_train_1m_4, p_train_05m_4, act_train_1m_4, act_train_05m_4, p_val_1m_4, p_val_05m_4, act_val_1m_4, act_val_05m_4 = predict_2_values(model_4, features4, val_features4, labels_4, val_labels_4, t_mean_1m, t_mean_05m, t_std_1m, t_std_05m)\n",
    "p_train_1m_5, p_train_05m_5, act_train_1m_5, act_train_05m_5, p_val_1m_5, p_val_05m_5, act_val_1m_5, act_val_05m_5 = predict_2_values(model_5, features5, val_features5, labels_5, val_labels_5, t_mean_1m, t_mean_05m, t_std_1m, t_std_05m)\n",
    "p_train_1m_6, p_train_05m_6, act_train_1m_6, act_train_05m_6, p_val_1m_6, p_val_05m_6, act_val_1m_6, act_val_05m_6 = predict_2_values(model_6, features6, val_features6, labels_6, val_labels_6, t_mean_1m, t_mean_05m, t_std_1m, t_std_05m)\n",
    "p_train_1m_7, p_train_05m_7, act_train_1m_7, act_train_05m_7, p_val_1m_7, p_val_05m_7, act_val_1m_7, act_val_05m_7 = predict_2_values(model_7, features7, val_features7, labels_7, val_labels_7, t_mean_1m, t_mean_05m, t_std_1m, t_std_05m)\n",
    "p_train_1m_8, p_train_05m_8, act_train_1m_8, act_train_05m_8, p_val_1m_8, p_val_05m_8, act_val_1m_8, act_val_05m_8 = predict_2_values(model_8, features8, val_features8, labels_8, val_labels_8, t_mean_1m, t_mean_05m, t_std_1m, t_std_05m)\n",
    "p_train_1m_9, p_train_05m_9, act_train_1m_9, act_train_05m_9, p_val_1m_9, p_val_05m_9, act_val_1m_9, act_val_05m_9 = predict_2_values(model_9, features9, val_features9, labels_9, val_labels_9, t_mean_1m, t_mean_05m, t_std_1m, t_std_05m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can plot the predicted vs observed values for the training and validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_scatter_plot('Dataset 1, 1m', p_val_1m_1, act_val_1m_1, p_train_1m_1, act_train_1m_1)\n",
    "create_scatter_plot('Dataset 2, 1m', p_val_1m_2, act_val_1m_2, p_train_1m_2, act_train_1m_2)\n",
    "create_scatter_plot('Dataset 3, 1m', p_val_1m_3, act_val_1m_3, p_train_1m_3, act_train_1m_3)\n",
    "create_scatter_plot('Dataset 4, 1m', p_val_1m_4, act_val_1m_4, p_train_1m_4, act_train_1m_4)\n",
    "create_scatter_plot('Dataset 5, 1m', p_val_1m_5, act_val_1m_5, p_train_1m_5, act_train_1m_5)\n",
    "create_scatter_plot('Dataset 6, 1m', p_val_1m_6, act_val_1m_6, p_train_1m_6, act_train_1m_6)\n",
    "create_scatter_plot('Dataset 7, 1m', p_val_1m_7, act_val_1m_7, p_train_1m_7, act_train_1m_7)\n",
    "create_scatter_plot('Dataset 8, 1m', p_val_1m_8, act_val_1m_8, p_train_1m_8, act_train_1m_8)\n",
    "create_scatter_plot('Dataset 9, 1m', p_val_1m_9, act_val_1m_9, p_train_1m_9, act_train_1m_9)\n",
    "\n",
    "create_scatter_plot('Dataset 1, 0-5m', p_val_05m_1, act_val_05m_1, p_train_05m_1, act_train_05m_1)\n",
    "create_scatter_plot('Dataset 2, 0-5m', p_val_05m_2, act_val_05m_2, p_train_05m_2, act_train_05m_2)\n",
    "create_scatter_plot('Dataset 3, 0-5m', p_val_05m_3, act_val_05m_3, p_train_05m_3, act_train_05m_3)\n",
    "create_scatter_plot('Dataset 4, 0-5m', p_val_05m_4, act_val_05m_4, p_train_05m_4, act_train_05m_4)\n",
    "create_scatter_plot('Dataset 5, 0-5m', p_val_05m_5, act_val_05m_5, p_train_05m_5, act_train_05m_5)\n",
    "create_scatter_plot('Dataset 6, 0-5m', p_val_05m_6, act_val_05m_6, p_train_05m_6, act_train_05m_6)\n",
    "create_scatter_plot('Dataset 7, 0-5m', p_val_05m_7, act_val_05m_7, p_train_05m_7, act_train_05m_7)\n",
    "create_scatter_plot('Dataset 8, 0-5m', p_val_05m_8, act_val_05m_8, p_train_05m_8, act_train_05m_8)\n",
    "create_scatter_plot('Dataset 9, 0-5m', p_val_05m_9, act_val_05m_9, p_train_05m_9, act_train_05m_9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_plot(act_val_1m_1, p_val_1m_1, 'Validation Dataset 1, 1m')\n",
    "ts_plot(act_val_05m_1, p_val_05m_1, 'Validation Dataset 1, 0-5m')\n",
    "ts_plot(act_val_1m_2, p_val_1m_2, 'Validation Dataset 2, 1m')\n",
    "ts_plot(act_val_05m_2, p_val_05m_2, 'Validation Dataset 2, 0-5m')\n",
    "ts_plot(act_val_1m_3, p_val_1m_3, 'Validation Dataset 3, 1m')\n",
    "ts_plot(act_val_05m_3, p_val_05m_3, 'Validation Dataset 3, 0-5m')\n",
    "ts_plot(act_val_1m_4, p_val_1m_4, 'Validation Dataset 4, 1m')\n",
    "ts_plot(act_val_05m_4, p_val_05m_4, 'Validation Dataset 4, 0-5m')\n",
    "ts_plot(act_val_1m_5, p_val_1m_5, 'Validation Dataset 5, 1m')\n",
    "ts_plot(act_val_05m_5, p_val_05m_5, 'Validation Dataset 5, 0-5m')\n",
    "ts_plot(act_val_1m_6, p_val_1m_6, 'Validation Dataset 6, 1m')\n",
    "ts_plot(act_val_05m_6, p_val_05m_6, 'Validation Dataset 6, 0-5m')\n",
    "ts_plot(act_val_1m_7, p_val_1m_7, 'Validation Dataset 7, 1m')\n",
    "ts_plot(act_val_05m_7, p_val_05m_7, 'Validation Dataset 7, 0-5m')\n",
    "ts_plot(act_val_1m_8, p_val_1m_8, 'Validation Dataset 8, 1m')\n",
    "ts_plot(act_val_05m_8, p_val_05m_8, 'Validation Dataset 8, 0-5m')\n",
    "ts_plot(act_val_1m_9, p_val_1m_9, 'Validation Dataset 9, 1m')\n",
    "ts_plot(act_val_05m_9, p_val_05m_9, 'Validation Dataset 9, 0-5m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through datasets 1-4 at 1m\n",
    "for i in range(1, 10):\n",
    "    act_train_1m = globals()[\"act_train_1m_\" + str(i)]\n",
    "    pred_train_1m = globals()[\"p_train_1m_\" + str(i)]\n",
    "    act_val_1m = globals()[\"act_val_1m_\" + str(i)]\n",
    "    pred_val_1m = globals()[\"p_val_1m_\" + str(i)]\n",
    "    print_error_metrics(i, act_train_1m, pred_train_1m, act_val_1m, pred_val_1m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and a 0-5m\n",
    "for i in range(1, 10):\n",
    "    act_train_05m = globals()[\"act_train_05m_\" + str(i)]\n",
    "    pred_train_05m = globals()[\"p_train_05m_\" + str(i)]\n",
    "    act_val_05m = globals()[\"act_val_05m_\" + str(i)]\n",
    "    pred_val_05m = globals()[\"p_val_05m_\" + str(i)]\n",
    "    print_error_metrics(i, act_train_05m, pred_train_05m, act_val_05m, pred_val_05m)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just a quick reminder of the baseline: \n",
    "\n",
    "1m baseline\n",
    "\n",
    "Mean Squared Error for 1m baseline : 0.26\n",
    "\n",
    "Mean Absolute Error for 1m baseline : 0.42\n",
    "\n",
    "0-5m baseline\n",
    "\n",
    "Mean Squared Error for 0-5m baseline : 0.11\n",
    "\n",
    "Mean Absolute Error for 0-5m baseline : 0.27\n",
    "\n",
    "Our model absolutely slays. I want to test a smaller network, but this might be a winner! Let's look at the SHAP before that, though."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_NW",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
